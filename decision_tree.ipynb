{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1uWSMCrKGWfK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a97U8AF9Qi4x"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(\"cc_data.csv\", encoding = \"UTF-8\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_X1 = pd.get_dummies(df[df.columns[df.columns != 'REALTYPE']].copy()) # get columns that are not 'good cx'\n",
        "df_X = pd.get_dummies(df_X1[df_X1.columns[df_X1.columns != 'ID']].copy())\n",
        "df_y = df['REALTYPE'].copy() # get the column named 'REALTYPE'; this is our label"
      ],
      "metadata": {
        "id": "nAkOVib61twb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=1)\n",
        "\n",
        "print (\"Number of training instances: \", len(X_train), \"\\nNumber of test instances: \", len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_usbvWjg4puH",
        "outputId": "56e2f2a1-050d-4dc9-e68d-b65220f66f32"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training instances:  28884 \n",
            "Number of test instances:  7221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normal DT**"
      ],
      "metadata": {
        "id": "eFEkNA2Ylc7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, roc_auc_score, roc_curve, recall_score, precision_score\n",
        "\n",
        "# Fix the random seed for decision tree classifier\n",
        "np.random.seed(seed=0)   \n",
        "dt = DecisionTreeClassifier(max_depth=None)\n",
        "dt_model = dt.fit(X_train,y_train)\n",
        "\n",
        "# Calculate accuracy of DT\n",
        "print('Decision Tree accuracy for training set: %f' % dt_model.score(X_train, y_train))\n",
        "print('Decision Tree accuracy for test set: %f' % dt_model.score(X_test, y_test))\n",
        "\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# Calculate F1 score, recall score and precision score\n",
        "f = f1_score(y_test , y_pred, average = 'weighted')\n",
        "recall = recall_score(y_test, y_pred)\n",
        "precision = precision = precision_score(y_test, y_pred)\n",
        "print('F1 score: %f' %f)\n",
        "print('recall score: %f' %recall)\n",
        "print('precision score: %f' %precision)\n",
        "print('AUC-ROC score: %f' %roc_auc_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43X-sH7h44iy",
        "outputId": "479bebf6-0515-4784-d2d9-25c2100ca419"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree accuracy for training set: 1.000000\n",
            "Decision Tree accuracy for test set: 0.988090\n",
            "f1 score: 0.987985\n",
            "recall score: 0.228070\n",
            "precision score: 0.236364\n",
            "AUC-ROC score: 0.611104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
        "y_pred = dt.predict(X_test)\n",
        "f = f1_score(y_true = y_test , y_pred = y_pred,average = 'weighted')\n",
        "print(f)\n",
        "# interpretation:\n",
        "# Because the data is imbalanced."
      ],
      "metadata": {
        "id": "kedWwFa37-Bh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e6bdb0a-25e8-4c43-89df-9b2a0edd83c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9879847866296657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For normal decision tree, we get accuracy 1 for train set and accuracy 0.988 for test set which are very good performance. However, becasue the data is imbalanced, the accuracy is not accurate enough. Therefore, we also calculate the recall score, precision score and F1 score, get 0.228, 0.236 and 0.988 respectively, and figure out that the number of false nagative and false positive instances are great. Besides, we get 0.611 for AUC-ROC score, which can aggregate measure the predictions is 61.1% correct.  \n"
      ],
      "metadata": {
        "id": "G0sw0F5PjG7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Near Miss Undersampling**"
      ],
      "metadata": {
        "id": "kD0qDngQlBPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn\n",
        "from imblearn.under_sampling import NearMiss \n",
        "undersample = NearMiss()\n",
        "# transform the dataset\n",
        "\n",
        "X_nm, y_nm = undersample.fit_resample(df_X, df_y)"
      ],
      "metadata": {
        "id": "QM2SLHpcbyDp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_nm, y_nm, test_size=0.2, random_state=1)\n",
        "\n",
        "print (\"Number of training instances: \", len(X_train), \"\\nNumber of test instances: \", len(X_test))\n",
        "\n",
        "\n",
        "np.random.seed(seed=0)   \n",
        "dt = DecisionTreeClassifier(max_depth=None)\n",
        "dt_model = dt.fit(X_train,y_train)\n",
        "\n",
        "# Calculate accuracy\n",
        "print('Decision Tree accuracy for training set: %f' % dt_model.score(X_train, y_train))\n",
        "print('Decision Tree accuracy for test set: %f' % dt_model.score(X_test, y_test))\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# Calculate F1 score, recall score and precision score\n",
        "f = f1_score(y_true = y_test , y_pred = y_pred,average = 'weighted')\n",
        "recall = recall_score(y_test, y_pred)\n",
        "precision = precision = precision_score(y_test, y_pred)\n",
        "print('F1 score: %f' %f)\n",
        "print('recall score: %f' %recall)\n",
        "print('precision score: %f' %precision)\n",
        "print('AUC-ROC score: %f' %roc_auc_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c0o2kW6c1om",
        "outputId": "502943f5-a060-4aa4-c196-a8106bc35645"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training instances:  422 \n",
            "Number of test instances:  106\n",
            "Decision Tree accuracy for training set: 1.000000\n",
            "Decision Tree accuracy for test set: 0.688679\n",
            "f1 score: 0.689095\n",
            "recall score: 0.606557\n",
            "precision score: 0.804348\n",
            "AUC-ROC score: 0.703279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### To reduce the effects of imbalance data, we use near miss undersampling, we get accuracy 1 for train set and accuracy 0.688 for test set which is much lower than decision tree result. We also calculate the recall score, precision score and F1 score, get 0.606, 0.804 and 0.689 respectively, and figure out that the number of false nagative and false positive instances are much smaller than normal decision tree. Besides, we get 0.703 for AUC-ROC score, which can aggregate measure the predictions is 70.3% correct. It is also much greater than normal decision tree result.\n"
      ],
      "metadata": {
        "id": "cUFUOmyjmHbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.value_counts(df_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trvl2jNCdIR9",
        "outputId": "4bc64f0f-921d-49b2-b674-d3f80f67809b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    35841\n",
              "1.0      264\n",
              "Name: REALTYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.value_counts(y_nm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG_vRCixfePO",
        "outputId": "67bc1f3c-f3f6-4a2c-cc75-23db0b6adc06"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    264\n",
              "1.0    264\n",
              "Name: REALTYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMOTE oversampling**"
      ],
      "metadata": {
        "id": "u2mh1be2liw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from numpy import mean\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SVMSMOTE\n",
        "from sklearn.datasets import make_classification\n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "\n",
        "counter = Counter(df_y)\n",
        "print('before', counter)\n",
        "sm = SMOTE()\n",
        "X_res, y_res = sm.fit_resample(df_X, df_y)\n",
        "counter = Counter(y_res)\n",
        "print('after', counter)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VR-BPTWLv3J",
        "outputId": "6d68c43a-2300-4a95-e596-80a776739f49"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before Counter({0.0: 35841, 1.0: 264})\n",
            "after Counter({0.0: 35841, 1.0: 35841})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_values = [1, 2, 3, 4, 5, 6, 7, 44, 60, 99]\n",
        "for k in k_values:\n",
        "\t# define pipeline\n",
        "\tmodel = DecisionTreeClassifier()\n",
        "\tover = SMOTE(sampling_strategy=0.1, k_neighbors=k)\n",
        "\tunder = RandomUnderSampler(sampling_strategy=0.5)\n",
        "\tsteps = [('over', over), ('under', under), ('model', model)]\n",
        "\tpipeline = Pipeline(steps=steps)\n",
        "\t# evaluate pipeline\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(pipeline, df_X, df_y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "\n",
        "\tscore = mean(scores)\n",
        "\tprint('> k=%d, Mean ROC AUC: %.3f' % (k, score))\n",
        "\n",
        "print('Decision Tree accuracy for training set: %f' % dt_model.score(X_train, y_train))\n",
        "print('Decision Tree accuracy for test set: %f' % dt_model.score(X_test, y_test))\n",
        "y_pred = dt.predict(X_test)\n",
        "f = f1_score(y_test , y_pred, average = 'weighted')\n",
        "recall = recall_score(y_test, y_pred)\n",
        "precision = precision = precision_score(y_test, y_pred)\n",
        "print('f1 score: %f' %f)\n",
        "print('recall score: %f' %recall)\n",
        "print('precision score: %f' %precision)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M6ljFxLfeUL",
        "outputId": "fd94116e-07c7-4399-bbd1-728bdcfb32a1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> k=1, Mean ROC AUC: 0.673\n",
            "> k=2, Mean ROC AUC: 0.664\n",
            "> k=3, Mean ROC AUC: 0.666\n",
            "> k=4, Mean ROC AUC: 0.671\n",
            "> k=5, Mean ROC AUC: 0.670\n",
            "> k=6, Mean ROC AUC: 0.660\n",
            "> k=7, Mean ROC AUC: 0.669\n",
            "> k=44, Mean ROC AUC: 0.671\n",
            "> k=60, Mean ROC AUC: 0.670\n",
            "> k=99, Mean ROC AUC: 0.665\n",
            "Decision Tree accuracy for training set: 1.000000\n",
            "Decision Tree accuracy for test set: 0.688679\n",
            "f1 score: 0.689095\n",
            "recall score: 0.606557\n",
            "precision score: 0.804348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####We use SMOTE oversampling to reduce the effects of imbalance data. we get accuracy 1 for train set and accuracy 0.689 for test set which is much lower than decision tree result. We also calculate the recall score, precision score and F1 score, get 0.607, 0.804 and 0.689 respectively, and figure out that the number of false nagative and false positive instances are much smaller than normal decision tree. Besides, by tring different K value for AUC-ROC score, AUC-ROC score are less than 0.68 which measure the predictions is less than 68% correct. But it is still much greater than normal decision tree result."
      ],
      "metadata": {
        "id": "RpeKAl7AyLFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using Validation\n"
      ],
      "metadata": {
        "id": "6nAYi0EMvUbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_rem, y_train, y_rem = train_test_split(df_X, df_y, train_size=0.8)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n",
        "\n",
        "print(X_train.shape), print(y_train.shape)\n",
        "print(X_valid.shape), print(y_valid.shape)\n",
        "print(X_test.shape), print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekCjcBwzBdto",
        "outputId": "77868395-242f-4d70-8d47-30c246fa2b52"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28884, 53)\n",
            "(28884,)\n",
            "(3610, 53)\n",
            "(3610,)\n",
            "(3611, 53)\n",
            "(3611,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###DT"
      ],
      "metadata": {
        "id": "E8fNbPIbCYmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas._libs.lib import fast_unique_multiple_list_gen\n",
        "\n",
        "np.random.seed(seed=3244)   \n",
        "dt = DecisionTreeClassifier()\n",
        "dt_model = dt.fit(X_train,y_train)\n",
        "\n",
        "print('Decision Tree accuracy for training set: %f' % dt_model.score(X_train, y_train))\n",
        "print('Decision Tree accuracy for validation set: %f' % dt_model.score(X_valid, y_valid))\n",
        "print('Decision Tree accuracy for test set: %f' % dt_model.score(X_test, y_test))\n",
        "\n",
        "y_pred_valid = dt.predict(X_valid)\n",
        "y_pred_test = dt.predict(X_test)\n",
        "\n",
        "f_valid = f1_score(y_valid , y_pred_valid, average = 'weighted')\n",
        "f_test = f1_score(y_test , y_pred_test, average = 'weighted')\n",
        "print('f1 score of valid set: %f' %f_valid)\n",
        "print('f1 score of test set: %f' %f_test)\n",
        "\n",
        "recall_valid = recall_score(y_valid, y_pred_valid)\n",
        "recall_test = recall_score(y_test, y_pred_test)\n",
        "print('recall score of valid set: %f' %recall_valid)\n",
        "print('recall score of test set: %f' %recall_test)\n",
        "\n",
        "precision_valid = precision_score(y_valid, y_pred_valid)\n",
        "precision_test = precision_score(y_test, y_pred_test)\n",
        "print('precision score of valid set: %f' %precision_valid)\n",
        "print('precision score of test set: %f' %precision_test)\n",
        "\n",
        "rocauc_valid = roc_auc_score(y_valid, y_pred_valid)\n",
        "rocauc_test = roc_auc_score(y_test, y_pred_test)\n",
        "print('AUC-ROC score of valid set: %f' %rocauc_valid)\n",
        "print('AUC-ROC score of test set: %f' %rocauc_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3JCAS86CaBL",
        "outputId": "b9216f65-0404-48cb-c6c5-9a5a1f6b8da1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree accuracy for training set: 1.000000\n",
            "Decision Tree accuracy for validation set: 0.988366\n",
            "Decision Tree accuracy for test set: 0.987538\n",
            "f1 score of valid set: 0.987904\n",
            "f1 score of test set: 0.988028\n",
            "recall score of valid set: 0.148148\n",
            "recall score of test set: 0.310345\n",
            "precision score of valid set: 0.173913\n",
            "precision score of test set: 0.264706\n",
            "AUC-ROC score of valid set: 0.571423\n",
            "AUC-ROC score of test set: 0.651683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####For normal decision tree, compared to not use validation, the accuracy for test set is slightly lower, but F1 score, recall score and precison score are much greater. Besides, AUC-ROC score of test set increases to 0.65 which is around 4% improving."
      ],
      "metadata": {
        "id": "bRtKhLtjzpbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Near Miss undersampling"
      ],
      "metadata": {
        "id": "kS52XIe2EpjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_nm, y_nm, test_size=0.2, random_state=1)\n",
        "\n",
        "X_train, X_rem, y_train, y_rem = train_test_split(X_nm, y_nm, train_size=0.8)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n",
        "\n",
        "print(X_train.shape), print(y_train.shape)\n",
        "print(X_valid.shape), print(y_valid.shape)\n",
        "print(X_test.shape), print(y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVwPUbzLEshD",
        "outputId": "cb69b2a8-1088-48ca-c0b1-814620d0edb9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(422, 53)\n",
            "(422,)\n",
            "(53, 53)\n",
            "(53,)\n",
            "(53, 53)\n",
            "(53,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(seed=3244)   \n",
        "dt = DecisionTreeClassifier()\n",
        "dt_model = dt.fit(X_train,y_train)\n",
        "\n",
        "print('Decision Tree accuracy for training set: %f' % dt_model.score(X_train, y_train))\n",
        "print('Decision Tree accuracy for validation set: %f' % dt_model.score(X_valid, y_valid))\n",
        "print('Decision Tree accuracy for test set: %f' % dt_model.score(X_test, y_test))\n",
        "\n",
        "y_pred_valid = dt.predict(X_valid)\n",
        "y_pred_test = dt.predict(X_test)\n",
        "\n",
        "f_valid = f1_score(y_valid , y_pred_valid, average = 'weighted')\n",
        "f_test = f1_score(y_test , y_pred_test, average = 'weighted')\n",
        "print('f1 score of valid set: %f' %f_valid)\n",
        "print('f1 score of test set: %f' %f_test)\n",
        "\n",
        "recall_valid = recall_score(y_valid, y_pred_valid)\n",
        "recall_test = recall_score(y_test, y_pred_test)\n",
        "print('recall score of valid set: %f' %recall_valid)\n",
        "print('recall score of test set: %f' %recall_test)\n",
        "\n",
        "precision_valid = precision_score(y_valid, y_pred_valid)\n",
        "precision_test = precision_score(y_test, y_pred_test)\n",
        "print('precision score of valid set: %f' %precision_valid)\n",
        "print('precision score of test set: %f' %precision_test)\n",
        "\n",
        "rocauc_valid = roc_auc_score(y_valid, y_pred_valid)\n",
        "rocauc_test = roc_auc_score(y_test, y_pred_test)\n",
        "print('AUC-ROC score of valid set: %f' %rocauc_valid)\n",
        "print('AUC-ROC score of test set: %f' %rocauc_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMLaxJM9Fpob",
        "outputId": "28c986cd-6523-414f-a12c-48c0f19988c8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree accuracy for training set: 1.000000\n",
            "Decision Tree accuracy for validation set: 0.773585\n",
            "Decision Tree accuracy for test set: 0.641509\n",
            "f1 score of valid set: 0.776025\n",
            "f1 score of test set: 0.645479\n",
            "recall score of valid set: 0.718750\n",
            "recall score of test set: 0.600000\n",
            "precision score of valid set: 0.884615\n",
            "precision score of test set: 0.521739\n",
            "AUC-ROC score of valid set: 0.787946\n",
            "AUC-ROC score of test set: 0.633333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####For DT with near miss undersampling, compared to not use validation, the accuracy, F1 score, recall score, precision score and AUC-ROC score of test set are all slightly lower. "
      ],
      "metadata": {
        "id": "Z72VbORI09ow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SMOTE oversampling"
      ],
      "metadata": {
        "id": "1uWSMCrKGWfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter = Counter(df_y)\n",
        "print('before', counter)\n",
        "sm = SMOTE(random_state=3244)\n",
        "X_res, y_res = sm.fit_resample(df_X, df_y)\n",
        "counter = Counter(y_res)\n",
        "print('after', counter)\n",
        "\n",
        "X_train, X_rem, y_train, y_rem = train_test_split(X_res, y_res, train_size=0.8)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n",
        "\n",
        "print(X_train.shape), print(y_train.shape)\n",
        "print(X_valid.shape), print(y_valid.shape)\n",
        "print(X_test.shape), print(y_test.shape)\n",
        "\n",
        "np.random.seed(seed=3244)   \n",
        "dt = DecisionTreeClassifier()\n",
        "dt_model = dt.fit(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x7U9Qi2GYqV",
        "outputId": "f76fbe6c-e81c-40bb-a215-4f21768eedfc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before Counter({0.0: 35841, 1.0: 264})\n",
            "after Counter({0.0: 35841, 1.0: 35841})\n",
            "(57345, 53)\n",
            "(57345,)\n",
            "(7168, 53)\n",
            "(7168,)\n",
            "(7169, 53)\n",
            "(7169,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "owC6JjSD1mjD"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}